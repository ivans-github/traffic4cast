{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import h5py\n",
    "import tarfile\n",
    "from fastai.basics import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from model import *\n",
    "\n",
    "WORKING_DIR = '../working'\n",
    "INPUT_DIR = '../input/traffic4cast2020'\n",
    "MODEL_DIR = '../input/traffic4cast2020models'\n",
    "MODEL_NAME = 'moscow_o070_m.pth'\n",
    "\n",
    "CITIES = ['MOSCOW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test_slots.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "with open(f'{INPUT_DIR}/test_slots.json', 'r') as json_file:\n",
    "    test_slots = json.load(json_file)\n",
    "    test_slots = {k:v for each in test_slots for k,v in each.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetO().cuda()\n",
    "state = torch.load(f'{MODEL_DIR}/{MODEL_NAME}')\n",
    "hasopt = set(state)=={'model', 'opt'}\n",
    "model_state = state['model'] if hasopt else state\n",
    "model.load_state_dict(model_state, strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear working directory\n",
    "!rm -r *\n",
    "\n",
    "for city in CITIES:\n",
    "    \n",
    "    print(city)\n",
    "    working_path = Path(f'{WORKING_DIR}/{city}')\n",
    "    \n",
    "    # Unzip data if it is not already done so\n",
    "    if not working_path.exists():\n",
    "        with tarfile.open(f'{INPUT_DIR}/{city}.tar') as tarred_file:\n",
    "            files = [tarinfo for tarinfo in tarred_file.getmembers()\n",
    "                     if tarinfo.name.startswith(f'{city}/testing/')\n",
    "                     or tarinfo.name.startswith(f'{city}/{city}_static')] # Only unzipping the testing folder and static file\n",
    "            tarred_file.extractall(members=files, path=WORKING_DIR)\n",
    "    \n",
    "    # load static features\n",
    "    with h5py.File(f'{working_path}/{city}_static_2019.h5', 'r') as static_file:\n",
    "        static_features = static_file.get('array')[()].astype(np.float32)\n",
    "        static_features = torch.from_numpy(static_features).permute(2, 0, 1)\n",
    "    static_features = static_features\n",
    "    \n",
    "    # Loop through each test date\n",
    "    for date, frame in tqdm(test_slots.items()):\n",
    "        \n",
    "        with h5py.File(f'{working_path}/testing/{date}_test.h5', 'r') as h5_file:\n",
    "            x = h5_file.get('array')[()]\n",
    "            \n",
    "        # Note dimension reordering, from (Batch Size, Time, Height, Width, Channels) to (Batch Size, Channels, Time, Height, Width)\n",
    "        x = np.transpose(x, (0, 4, 1, 2, 3))\n",
    "        x = torch.from_numpy(x).float()\n",
    "            \n",
    "        ##################################################################################################\n",
    "        # Calculate output\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            N, C, D, H, W = x.shape\n",
    "            x = x.reshape(N, C*D, H, W)\n",
    "            s = torch.stack(N*[static_features], dim=0)\n",
    "            t = torch.ones(N, 1, H, W)\n",
    "            for j in range(N):\n",
    "                t[j] = t[j] * frame[j] * 255. / (288. - 12)\n",
    "            x = torch.cat([x, s, t], dim=1)\n",
    "                \n",
    "            if x.shape[0] > 3:\n",
    "                y1 = model(x[:3].cuda()).cpu()\n",
    "                y2 = model(x[3:].cuda()).cpu()\n",
    "                y = torch.cat([y1, y2])\n",
    "                del y1, y2\n",
    "            else:\n",
    "                y = model(x.cuda()).cpu()\n",
    "            \n",
    "            y = torch.round(y)\n",
    "            y = torch.clamp(y, min=0, max=255)\n",
    "        ##################################################################################################\n",
    "        \n",
    "        # Dimension reordering\n",
    "        y = y.permute(0, 2, 3, 4, 1).byte()\n",
    "        # Assume output.shape == input.shape, hence slice out the bit required for submission\n",
    "        y = y[:,[0,1,2,5,8,11],:,:,:8]\n",
    "        \n",
    "        with h5py.File(f'{working_path}/{date}_test.h5', 'w') as h5_file:\n",
    "            h5_file.create_dataset('array', data=y, compression=\"gzip\", compression_opts=6)\n",
    "            \n",
    "        del x, y\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Delete the used files to save disk space...\n",
    "        os.remove(f'{working_path}/testing/{date}_test.h5')\n",
    "        \n",
    "    # Delete data folder\n",
    "    shutil.rmtree(f'{working_path}/testing')\n",
    "    os.remove(f'{working_path}/{city}_static_2019.h5')\n",
    "\n",
    "# Create .zip file\n",
    "!zip -r0 submission.zip ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
